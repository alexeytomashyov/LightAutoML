{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "db9812420e9f1e08d51514d493ec8074022af79b4a6254804ccdc86bfed24f70"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "#### In this tutorial we will implement distillation of complex model's knowledge to simpler models. A complex model called teacher is TabilarAutoMl object. Simpler models called students are BoostCB and BoostLGBM objects."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.dataset.roles import DatetimeRole\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.addons.distillation import Distiller\n",
    "from lightautoml.utils.profiler import Profiler"
   ]
  },
  {
   "source": [
    "### 1. Some Setups"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 2000\n",
    "TARGET_NAME = 'TARGET'\n",
    "\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "source": [
    "By default, profiling decorators are turned off for speed gain and memory usage reduction. If you want to see a profiling report after using LAMA, you need to turn on the decorators using a command below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Profiler()\n",
    "p.change_deco_settings({'enabled': True})"
   ]
  },
  {
   "source": [
    "### 2. Data loading and preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv('example_data/test_data_files/sampled_app_train.csv')\n",
    "\n",
    "data['BIRTH_DATE'] = (np.datetime64('2018-01-01') + data['DAYS_BIRTH'].astype(np.dtype('timedelta64[D]'))).astype(str)\n",
    "data['EMP_DATE'] = (np.datetime64('2018-01-01') + np.clip(data['DAYS_EMPLOYED'], None, 0).astype(np.dtype('timedelta64[D]'))\n",
    "                    ).astype(str)\n",
    "\n",
    "data['report_dt'] = np.datetime64('2018-01-01')\n",
    "data['constant'] = 1\n",
    "data['allnan'] = np.nan\n",
    "data.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED'], axis=1, inplace=True)\n",
    "\n",
    "train, test = train_test_split(data, test_size=2000, random_state=RANDOM_STATE)"
   ]
  },
  {
   "source": [
    "### 3. AutoML and distiller creation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = {'target': 'TARGET',\n",
    "         DatetimeRole(base_date=True, seasonality=(), base_feats=False): 'report_dt'}\n",
    "\n",
    "task = Task('binary')\n",
    "\n",
    "automl = TabularAutoML(task=task, timeout=30, general_params={'verbose': 0})\n",
    "distiller = Distiller(automl)"
   ]
  },
  {
   "source": [
    "### 4. Distiller fitting and evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 25.034852027893066 secs\n",
      "Time limit exceeded after calculating fold 1\n",
      "Time left 22.61545205116272\n",
      "Time limit exceeded after calculating fold 0\n",
      "Time limit exceeded after calculating fold 3\n",
      "Time limit exceeded after calculating fold 3\n",
      "Time left 2.8722121715545654\n",
      "Time limit exceeded in one of the tasks. AutoML will blend level 1 models.                                         \n",
      "Try to set higher time limits or use Profiler to find bottleneck and optimize Pipelines settings\n",
      "Teacher TEST ROC AUC: 0.7453926944883353\n"
     ]
    }
   ],
   "source": [
    "distiller.fit(train, roles=roles)\n",
    "test_pred = distiller.predict(test)\n",
    "print('Teacher TEST ROC AUC: {}'.format(roc_auc_score(test[roles['target']].values, test_pred.data[:, 0])))"
   ]
  },
  {
   "source": [
    "### 5. Evaluation of the students on true labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 9999999997.97606 secs\n",
      "Time left 9999999992.295929\n",
      "\n",
      "\n",
      "Layer 1 ...\n",
      "Train process start. Time left 9999999997.823078 secs\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "Time left 9999999993.712234\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            roc_auc_score accuracy_score\n",
       "Lvl_0_Pipe_0_Mod_0_CatBoost       0.73866         0.9275\n",
       "Lvl_0_Pipe_0_Mod_0_LightGBM      0.726759         0.9275"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc_score</th>\n      <th>accuracy_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Lvl_0_Pipe_0_Mod_0_CatBoost</th>\n      <td>0.73866</td>\n      <td>0.9275</td>\n    </tr>\n    <tr>\n      <th>Lvl_0_Pipe_0_Mod_0_LightGBM</th>\n      <td>0.726759</td>\n      <td>0.9275</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "distiller.distill(train, labels=train['TARGET'])\n",
    "\n",
    "metrics = distiller.eval_metrics(test, metrics=[roc_auc_score, accuracy_score])\n",
    "metrics"
   ]
  },
  {
   "source": [
    "### 6. Teacher knowledge distillation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Time limit exceeded after calculating fold 2\n",
      "Time limit exceeded after calculating fold 1\n",
      "Time limit exceeded after calculating fold 3\n",
      "Time limit exceeded after calculating fold 1\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "[LightGBM] [Warning] verbosity is set=-1, verbose=0 will be ignored. Current value: verbosity=-1\n",
      "Best model after distillation: Lvl_0_Pipe_0_Mod_0_LightGBM\n"
     ]
    }
   ],
   "source": [
    "automl = TabularAutoML(task=task, timeout=30, verbose=0)\n",
    "distiller = Distiller(automl)\n",
    "distiller.fit(train, roles=roles)\n",
    "best_model = distiller.distill(train)\n",
    "print('Best model after distillation: {}'.format(best_model.levels[0][0].ml_algos[0].name))"
   ]
  },
  {
   "source": [
    "### 7. Evaluation of the students on labels derived from teacher"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            roc_auc_score accuracy_score\n",
       "Lvl_0_Pipe_0_Mod_0_CatBoost      0.742482         0.9275\n",
       "Lvl_0_Pipe_0_Mod_0_LightGBM      0.742203         0.9275"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>roc_auc_score</th>\n      <th>accuracy_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Lvl_0_Pipe_0_Mod_0_CatBoost</th>\n      <td>0.742482</td>\n      <td>0.9275</td>\n    </tr>\n    <tr>\n      <th>Lvl_0_Pipe_0_Mod_0_LightGBM</th>\n      <td>0.742203</td>\n      <td>0.9275</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "metrics = distiller.eval_metrics(test, metrics=[roc_auc_score,accuracy_score])\n",
    "metrics"
   ]
  },
  {
   "source": [
    "### 8. Profiling report creation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.profile('profiling_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}